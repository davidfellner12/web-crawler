# Web Crawler

A simple Python web crawler that recursively crawls pages within a single domain, respecting robots.txt, extracting links, and saving page content.

## Features

- Domain-restricted recursive crawling
- robots.txt compliance
- Polite crawling with delay
- Local storage of pages

## Setup

1. Clone this repo:

```bash
cd C:\Users\david\Desktop\Web_Crawler\MY_ACTUAL_CRAWLER
python -m crawler.main
