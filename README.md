# ğŸ•·ï¸ Python Web Crawler

A simple Python web crawler that recursively crawls pages within a single domain, respects `robots.txt`, extracts links and metadata, and saves page content.

## âœ¨ Features

- âœ… Domain-restricted recursive crawling
- âœ… `robots.txt` compliance
- âœ… Polite crawling (1s delay between requests)
- âœ… Redis-based URL queue and visited set
- âœ… Page content and metadata storage

---

## ğŸš€ Quickstart (with Docker)

You need **Docker** and **Docker Compose** installed.

1. **Clone the repository**:

```bash
git clone https://github.com/davidfellner12/web-crawler.git
cd my-crawler
