# Web Crawler

A simple Python web crawler that recursively crawls pages within a single domain, respecting robots.txt, extracting links, and saving page content.

## Features

- Domain-restricted recursive crawling
- robots.txt compliance
- Polite crawling with delay
- Local storage of pages

## Setup

1. Clone this repo:

```bash
git clone https://github.com/davidfellner12/web-crawler.git
cd web-crawler
